{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQhGwUUBVLxo",
        "outputId": "f11959d4-a964-462c-8b07-e314f3148ab5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NTumwiu1UAZx"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**"
      ],
      "metadata": {
        "id": "t-CHOUWaVUDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mytext = \"\"\"\n",
        "Hello Mr. Smith, How are you doing today? The weather is great, and Python is awesome.\n",
        "\n",
        "The sky is pinkish-blue. You shouldn't eat cardboard.\n",
        "\"\"\"\n",
        "\n",
        "print(mytext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW6PlJuqVHxT",
        "outputId": "76f9f1b7-beb8-4318-f074-2c43e6cdc0a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hello Mr. Smith, How are you doing today? The weather is great, and Python is awesome. \n",
            "\n",
            "The sky is pinkish-blue. You shouldn't eat cardboard.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Tokenization**"
      ],
      "metadata": {
        "id": "JWOWPGKvV0Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpY2tZiqWWFx",
        "outputId": "6cf262c9-611b-4782-ea41-b9e55843098e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "my_text_tokens = word_tokenize(mytext)\n",
        "\n",
        "print(my_text_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACrJRI5AViFe",
        "outputId": "38e2f186-7f0f-4a4c-e0ef-1097a7ce6858"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Mr.', 'Smith', ',', 'How', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', ',', 'and', 'Python', 'is', 'awesome', '.', 'The', 'sky', 'is', 'pinkish-blue', '.', 'You', 'should', \"n't\", 'eat', 'cardboard', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_text_tokens[0])\n",
        "print(my_text_tokens[1])\n",
        "print(my_text_tokens[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUpPNG3DWsAL",
        "outputId": "d0efa87d-abed-4d2d-daee-9b5969edb970"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "Mr.\n",
            "Smith\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentence Tokenization**"
      ],
      "metadata": {
        "id": "kpOkKYX1V8t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "my_sent_tokens = sent_tokenize(mytext)\n",
        "\n",
        "print(my_sent_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLpM9-MYV-wy",
        "outputId": "3ddda4cb-ceae-47bb-cb17-8d7c5fe01436"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\nHello Mr. Smith, How are you doing today?', 'The weather is great, and Python is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_sent_tokens[0])\n",
        "print(my_sent_tokens[1])\n",
        "print(my_sent_tokens[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsq9tqZzWxW_",
        "outputId": "1fd5be1e-9644-4e63-9146-aa78a543f790"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hello Mr. Smith, How are you doing today?\n",
            "The weather is great, and Python is awesome.\n",
            "The sky is pinkish-blue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Blankline Tokenization**"
      ],
      "metadata": {
        "id": "7jdCIuvlWBqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import blankline_tokenize\n",
        "\n",
        "my_blankline_tokens = blankline_tokenize(mytext)\n",
        "\n",
        "print(my_blankline_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZrPC9wyWD90",
        "outputId": "c9790125-e239-42d8-8ff6-b6f036d0d33f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\nHello Mr. Smith, How are you doing today? The weather is great, and Python is awesome.', \"The sky is pinkish-blue. You shouldn't eat cardboard.\\n\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_blankline_tokens[0])\n",
        "print()\n",
        "print(my_blankline_tokens[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6gae1r_XBJX",
        "outputId": "97d8049e-87ff-48bb-b75c-32d0fe75e3eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hello Mr. Smith, How are you doing today? The weather is great, and Python is awesome.\n",
            "\n",
            "The sky is pinkish-blue. You shouldn't eat cardboard.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frequency distribution**"
      ],
      "metadata": {
        "id": "Wpy6sBNdZD_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "fdist = FreqDist()"
      ],
      "metadata": {
        "id": "4EIdlYy8XM0s"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mytext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkhXsApUbFdO",
        "outputId": "b2451405-070d-4839-e4b9-ae433cc888dd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hello Mr. Smith, How are you doing today? The weather is great, and Python is awesome. \n",
            "\n",
            "The sky is pinkish-blue. You shouldn't eat cardboard.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "my_text_tokens = word_tokenize(mytext)\n",
        "\n",
        "print(my_text_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXMguR-VbM5N",
        "outputId": "bed3f1dd-4a44-4436-f879-215218710a00"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Mr.', 'Smith', ',', 'How', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', ',', 'and', 'Python', 'is', 'awesome', '.', 'The', 'sky', 'is', 'pinkish-blue', '.', 'You', 'should', \"n't\", 'eat', 'cardboard', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in my_text_tokens:\n",
        "  fdist[word.lower()] += 1\n",
        "\n",
        "fdist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRurswdibOI3",
        "outputId": "9ba37f63-f6cb-418f-9df2-19304a0d6083"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'is': 3, '.': 3, ',': 2, 'you': 2, 'the': 2, 'hello': 1, 'mr.': 1, 'smith': 1, 'how': 1, 'are': 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdist_top_10 = fdist.most_common(10)\n",
        "fdist_top_10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2yWA_oBbk8_",
        "outputId": "a3649ca9-5c8f-45df-93d6-e68770e2cf3b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('is', 3),\n",
              " ('.', 3),\n",
              " (',', 2),\n",
              " ('you', 2),\n",
              " ('the', 2),\n",
              " ('hello', 1),\n",
              " ('mr.', 1),\n",
              " ('smith', 1),\n",
              " ('how', 1),\n",
              " ('are', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Types of token**\n",
        "- Bigrams - Tokens of two consecutive words\n",
        "- Trigrams - Tokens of three consecutive words\n",
        "- Ngrams - Tokens of n-number of consecutive words"
      ],
      "metadata": {
        "id": "ietzGEq9ZIet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"The most beautiful things in the world cannot be seen or even touched, they must be felt with the heart\"\n",
        "\n",
        "quotes_token = nltk.word_tokenize(string)\n",
        "print(quotes_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "856HSOVHZRRb",
        "outputId": "94225c44-f763-44e8-ef35-9b6c83719451"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'most', 'beautiful', 'things', 'in', 'the', 'world', 'can', 'not', 'be', 'seen', 'or', 'even', 'touched', ',', 'they', 'must', 'be', 'felt', 'with', 'the', 'heart']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quotes_bigram = nltk.bigrams(quotes_token)\n",
        "quotes_bigram = list(quotes_bigram)\n",
        "print(quotes_bigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhOukY3Pczok",
        "outputId": "6c2458fb-0ad7-4ec7-eb02-ce56c276b715"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'most'), ('most', 'beautiful'), ('beautiful', 'things'), ('things', 'in'), ('in', 'the'), ('the', 'world'), ('world', 'can'), ('can', 'not'), ('not', 'be'), ('be', 'seen'), ('seen', 'or'), ('or', 'even'), ('even', 'touched'), ('touched', ','), (',', 'they'), ('they', 'must'), ('must', 'be'), ('be', 'felt'), ('felt', 'with'), ('with', 'the'), ('the', 'heart')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quotes_trigram = nltk.trigrams(quotes_token)\n",
        "quotes_trigram = list(quotes_trigram)\n",
        "print(quotes_trigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-1TOJw6c-C2",
        "outputId": "7ed98213-3ce5-4cc6-c1f6-e83227711859"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'most', 'beautiful'), ('most', 'beautiful', 'things'), ('beautiful', 'things', 'in'), ('things', 'in', 'the'), ('in', 'the', 'world'), ('the', 'world', 'can'), ('world', 'can', 'not'), ('can', 'not', 'be'), ('not', 'be', 'seen'), ('be', 'seen', 'or'), ('seen', 'or', 'even'), ('or', 'even', 'touched'), ('even', 'touched', ','), ('touched', ',', 'they'), (',', 'they', 'must'), ('they', 'must', 'be'), ('must', 'be', 'felt'), ('be', 'felt', 'with'), ('felt', 'with', 'the'), ('with', 'the', 'heart')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quotes_ngram = nltk.ngrams(quotes_token, 5)\n",
        "quotes_ngram = list(quotes_ngram)\n",
        "print(quotes_ngram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUFxqpGDdEnt",
        "outputId": "30821b2a-ae29-415e-cf8e-f72fa4fbe2a8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'most', 'beautiful', 'things', 'in'), ('most', 'beautiful', 'things', 'in', 'the'), ('beautiful', 'things', 'in', 'the', 'world'), ('things', 'in', 'the', 'world', 'can'), ('in', 'the', 'world', 'can', 'not'), ('the', 'world', 'can', 'not', 'be'), ('world', 'can', 'not', 'be', 'seen'), ('can', 'not', 'be', 'seen', 'or'), ('not', 'be', 'seen', 'or', 'even'), ('be', 'seen', 'or', 'even', 'touched'), ('seen', 'or', 'even', 'touched', ','), ('or', 'even', 'touched', ',', 'they'), ('even', 'touched', ',', 'they', 'must'), ('touched', ',', 'they', 'must', 'be'), (',', 'they', 'must', 'be', 'felt'), ('they', 'must', 'be', 'felt', 'with'), ('must', 'be', 'felt', 'with', 'the'), ('be', 'felt', 'with', 'the', 'heart')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**\n",
        "- Normalize a word to its base form or root form\n",
        "- Affection, Affects, Affections, Affected, Affecting =-> Affect\n",
        "- Stemming algorithm works by cutting the ends or beginning of the words and taking into account the root or base form.\n",
        "\n",
        "Three major stemmer\n",
        "- PorterStemmer\n",
        "- LancasterStemmer\n",
        "- SnowballStemmer"
      ],
      "metadata": {
        "id": "WER5-RArhRLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "pst = PorterStemmer()\n",
        "pst.stem('having')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1NmVgC1QdTf4",
        "outputId": "5f8ca92a-63ab-4f56-b49a-615685056f0a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word_to_stem = ['give' , 'giving' , 'given' , 'gave']\n",
        "#word_to_stem = ['argue' , 'argued' , 'argues' , 'arguing']\n",
        "word_to_stem = ['eating' , 'eats' , 'eat' , 'ate' , 'eaten']\n",
        "\n",
        "for word in word_to_stem:\n",
        "  print(word + \" : \" + pst.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0lmxYaSicdY",
        "outputId": "0de9425a-0604-441c-d13e-d478cec1e1e9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating : eat\n",
            "eats : eat\n",
            "eat : eat\n",
            "ate : ate\n",
            "eaten : eaten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "lst = LancasterStemmer()\n",
        "lst.stem('having')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3Vqc_Pv-i-MS",
        "outputId": "2f7a5fca-e7e3-420b-ed02-702bac5588f7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word_to_stem = ['give' , 'giving' , 'given' , 'gave']\n",
        "#word_to_stem = ['argue' , 'argued' , 'argues' , 'arguing']\n",
        "word_to_stem = ['eating' , 'eats' , 'eat' , 'ate' , 'eaten']\n",
        "\n",
        "for word in word_to_stem:\n",
        "  print(word + \" : \" + lst.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO9Th8PzjWdj",
        "outputId": "5fc78700-8d66-4e06-d00e-31308291bdfb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating : eat\n",
            "eats : eat\n",
            "eat : eat\n",
            "ate : at\n",
            "eaten : eat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "sbst = SnowballStemmer('english')\n",
        "sbst.stem('having')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JraqbpoljhYa",
        "outputId": "7d6490bb-f4df-47dc-91c3-d07eaac815d7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_stem = ['eating' , 'eats' , 'eat' , 'ate' , 'eaten']\n",
        "\n",
        "for word in word_to_stem:\n",
        "  print(word + \" : \" + sbst.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw41UihBkFiX",
        "outputId": "1ccefba8-e9bf-4802-8a37-5bb06825116c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating : eat\n",
            "eats : eat\n",
            "eat : eat\n",
            "ate : ate\n",
            "eaten : eaten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatization**"
      ],
      "metadata": {
        "id": "vHh2-wxLhWfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWs4YfiMkrXN",
        "outputId": "9319081e-2f20-4b5a-f0b9-137f427a6685"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "word_lem = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "yVg3BStNhYAP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#words = ['study' , 'studies' , 'studying']\n",
        "words = [\"running\" , \"ran\" , \"runs\" , \"runner\"]\n",
        "\n",
        "for word in words:\n",
        "  print(word , '-' , word_lem.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9BzaJrRkego",
        "outputId": "3a075f87-3035-4fe8-d25d-c7383884703b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running - running\n",
            "ran - ran\n",
            "runs - run\n",
            "runner - runner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stop Words**\n",
        "- for identifying and removal of stopwords we require tokens."
      ],
      "metadata": {
        "id": "urju274QhY3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIYD-NZio2c-",
        "outputId": "8439ff3a-8d0d-4486-d00f-9c03f49b1a89"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjOuRILqhaAY",
        "outputId": "ffb57636-008f-4596-d108-9aef4616270d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(stopwords.words('english')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ErgORImo5ay",
        "outputId": "f005e4d6-c7e9-4bea-94b1-e5564153ad20"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mytext = \"\"\"\n",
        "Hello Mr. Smith, How are you doing today? The weather is great, and Python is awesome.\n",
        "\n",
        "The sky is pinkish-blue. You shouldn't eat cardboard.\n",
        "\"\"\"\n",
        "\n",
        "print(mytext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itbVNAFJo5e7",
        "outputId": "c003280e-ba02-49f7-c365-2b6f03c4eab2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hello Mr. Smith, How are you doing today? The weather is great, and Python is awesome. \n",
            "\n",
            "The sky is pinkish-blue. You shouldn't eat cardboard.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mytext.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boL2NK8fuXOe",
        "outputId": "8357e843-f660-4832-af68-f04fbccc8043"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Mr.', 'Smith,', 'How', 'are', 'you', 'doing', 'today?', 'The', 'weather', 'is', 'great,', 'and', 'Python', 'is', 'awesome.', 'The', 'sky', 'is', 'pinkish-blue.', 'You', \"shouldn't\", 'eat', 'cardboard.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_text_tokens = nltk.word_tokenize(mytext)\n",
        "print(my_text_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy8iUCkopCmV",
        "outputId": "10c690b0-e722-4fda-ead4-8747377fcab7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Mr.', 'Smith', ',', 'How', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', ',', 'and', 'Python', 'is', 'awesome', '.', 'The', 'sky', 'is', 'pinkish-blue', '.', 'You', 'should', \"n't\", 'eat', 'cardboard', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_stop_word_removal = []\n",
        "for word in my_text_tokens:\n",
        "  if word.lower() not in stopwords.words('english'):\n",
        "    post_stop_word_removal.append(word)\n",
        "\n",
        "print(post_stop_word_removal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY6qDgDFqxAn",
        "outputId": "edfbec51-f6e9-41f1-a8de-55e6b9869473"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Mr.', 'Smith', ',', 'today', '?', 'weather', 'great', ',', 'Python', 'awesome', '.', 'sky', 'pinkish-blue', '.', \"n't\", 'eat', 'cardboard', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_text_tokens_no_stop_words = [word for word in my_text_tokens if word.lower() not in stopwords.words('english')]\n",
        "print(my_text_tokens_no_stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiHHH45-pPr9",
        "outputId": "e28064cc-713b-4f5b-f587-ce8645f6f4c6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Mr.', 'Smith', ',', 'today', '?', 'weather', 'great', ',', 'Python', 'awesome', '.', 'sky', 'pinkish-blue', '.', \"n't\", 'eat', 'cardboard', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Punctuations**"
      ],
      "metadata": {
        "id": "dTOaflPKhbQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "punctuations = re.compile(r'[-.?!,:;()\\'|0-9]')"
      ],
      "metadata": {
        "id": "m5noxX-MhcxG"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_punc_removal = []\n",
        "for word in my_text_tokens_no_stop_words:\n",
        "  word = punctuations.sub('',word)\n",
        "  post_punc_removal.append(word)\n",
        "\n",
        "print(post_punc_removal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPWLoNoErzJO",
        "outputId": "ca8a54a8-8dd4-44fe-bf85-963cdfd0163b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Mr', 'Smith', '', 'today', '', 'weather', 'great', '', 'Python', 'awesome', '', 'sky', 'pinkishblue', '', 'nt', 'eat', 'cardboard', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POS Tagging**"
      ],
      "metadata": {
        "id": "qtQkxYLThdsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCw0xwfZw5xS",
        "outputId": "c2bda96c-2626-4d99-a276-a920fb6a760a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Joy is natural when it comes to singing'\n",
        "\n",
        "s_token = nltk.word_tokenize(text)\n",
        "print(s_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwtVfMI4hfNK",
        "outputId": "842ba663-cabd-439d-9ae7-7bf497c53265"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Joy', 'is', 'natural', 'when', 'it', 'comes', 'to', 'singing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in s_token:\n",
        "  print(nltk.pos_tag([token]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miHq4vC8wypb",
        "outputId": "5364350e-336f-40ba-c386-f028db021fbb"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Joy', 'NN')]\n",
            "[('is', 'VBZ')]\n",
            "[('natural', 'JJ')]\n",
            "[('when', 'WRB')]\n",
            "[('it', 'PRP')]\n",
            "[('comes', 'VBZ')]\n",
            "[('to', 'TO')]\n",
            "[('singing', 'VBG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Abbreviation Meaning**\n",
        "\n",
        "    CC - coordinating conjunction\n",
        "    CD - cardinal digit\n",
        "    DT - determiner\n",
        "    EX - existential there\n",
        "    FW - foreign word\n",
        "    IN - preposition/subordinating conjunction\n",
        "    JJ - This NLTK POS Tag is an adjective (large)\n",
        "    JJR - adjective, comparative (larger)\n",
        "    JJS - adjective, superlative (largest)\n",
        "    LS - list market\n",
        "    MD - modal (could, will)\n",
        "    NN - noun, singular (cat, tree)\n",
        "    NNS - noun plural (desks)\n",
        "    NNP - proper noun, singular (sarah)\n",
        "    NNPS - proper noun, plural (indians or americans)\n",
        "    PDT - predeterminer (all, both, half)\n",
        "    POS - possessive ending (parent\\ ‘s)\n",
        "    PRP - personal pronoun (hers, herself, him, himself)\n",
        "    PRP$ - possessive pronoun (her, his, mine, my, our )\n",
        "    RB - adverb (occasionally, swiftly)\n",
        "    RBR - adverb, comparative (greater)\n",
        "    RBS - adverb, superlative (biggest)\n",
        "    RP - particle (about)\n",
        "    TO - infinite marker (to)\n",
        "    UH - interjection (goodbye)\n",
        "    VB - verb (ask)\n",
        "    VBG - verb gerund (judging)\n",
        "    VBD - verb past tense (pleaded)\n",
        "    VBN - verb past participle (reunified)\n",
        "    VBP - verb, present tense not 3rd person singular(wrap)\n",
        "    VBZ - verb, present tense with 3rd person singular (bases)\n",
        "    WDT - wh-determiner (that, what)\n",
        "    WP wh- pronoun (who)\n",
        "    WRB wh- adverb (how)"
      ],
      "metadata": {
        "id": "7tXDnHdnxPWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mytext = \"\"\"\n",
        "Hello Mr. Smith, How are you doing today? The weather is great, and Python is awesome.\n",
        "\n",
        "The sky is pinkish-blue. You shouldn't eat cardboard.\n",
        "\"\"\"\n",
        "\n",
        "print(mytext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG9Us47kw3Ow",
        "outputId": "44342631-f027-4411-d905-50f5831afc49"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hello Mr. Smith, How are you doing today? The weather is great, and Python is awesome. \n",
            "\n",
            "The sky is pinkish-blue. You shouldn't eat cardboard.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_token = nltk.word_tokenize(mytext)\n",
        "for token in s_token:\n",
        "  print(nltk.pos_tag([token]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3Y36VlNxcH5",
        "outputId": "279d660f-8293-4c20-d17c-c537c75e3b15"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hello', 'NN')]\n",
            "[('Mr.', 'NNP')]\n",
            "[('Smith', 'NNP')]\n",
            "[(',', ',')]\n",
            "[('How', 'WRB')]\n",
            "[('are', 'VBP')]\n",
            "[('you', 'PRP')]\n",
            "[('doing', 'VBG')]\n",
            "[('today', 'NN')]\n",
            "[('?', '.')]\n",
            "[('The', 'DT')]\n",
            "[('weather', 'NN')]\n",
            "[('is', 'VBZ')]\n",
            "[('great', 'JJ')]\n",
            "[(',', ',')]\n",
            "[('and', 'CC')]\n",
            "[('Python', 'NN')]\n",
            "[('is', 'VBZ')]\n",
            "[('awesome', 'NN')]\n",
            "[('.', '.')]\n",
            "[('The', 'DT')]\n",
            "[('sky', 'NN')]\n",
            "[('is', 'VBZ')]\n",
            "[('pinkish-blue', 'NN')]\n",
            "[('.', '.')]\n",
            "[('You', 'PRP')]\n",
            "[('should', 'MD')]\n",
            "[(\"n't\", 'RB')]\n",
            "[('eat', 'NN')]\n",
            "[('cardboard', 'NN')]\n",
            "[('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Syntax tree**\n",
        "- word tokenization\n",
        "- pos tagging\n",
        "- syntax tree"
      ],
      "metadata": {
        "id": "epNhO6o7xqGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install svgling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJVBXgm0yoYn",
        "outputId": "7b9597fb-512f-4a65-82fb-cac2029518ee"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting svgling\n",
            "  Downloading svgling-0.5.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting svgwrite (from svgling)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading svgling-0.5.0-py3-none-any.whl (31 kB)\n",
            "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: svgwrite, svgling\n",
            "Successfully installed svgling-0.5.0 svgwrite-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"The big cat ate the little mouse who was after the fresh cheese\"\n",
        "\n",
        "new_text_pos = nltk.pos_tag(nltk.word_tokenize(new_text))\n",
        "new_text_pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuCmGpnwxhlr",
        "outputId": "dc40f358-58fd-445b-aac4-0526abc4f4b3"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('big', 'JJ'),\n",
              " ('cat', 'NN'),\n",
              " ('ate', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('little', 'JJ'),\n",
              " ('mouse', 'NN'),\n",
              " ('who', 'WP'),\n",
              " ('was', 'VBD'),\n",
              " ('after', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('fresh', 'JJ'),\n",
              " ('cheese', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grammer_np = r\"NP: {<DT><JJ><NN>}\"\n",
        "\n",
        "chunk_parser = nltk.RegexpParser(grammer_np)\n",
        "chunk_parser.parse(new_text_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "wXTv5HtIyArW",
        "outputId": "5e265db2-8823-4610-8040-8996afc4553e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP', [('The', 'DT'), ('big', 'JJ'), ('cat', 'NN')]), ('ate', 'VBD'), Tree('NP', [('the', 'DT'), ('little', 'JJ'), ('mouse', 'NN')]), ('who', 'WP'), ('was', 'VBD'), ('after', 'IN'), Tree('NP', [('the', 'DT'), ('fresh', 'JJ'), ('cheese', 'NN')])])"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,616.0,168.0\" width=\"616px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"19.4805%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">The</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"20px\" y2=\"48px\" /><svg width=\"33.3333%\" x=\"33.3333%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">big</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /><svg width=\"33.3333%\" x=\"66.6667%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">cat</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"83.3333%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.74026%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.49351%\" x=\"19.4805%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ate</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"20px\" y2=\"48px\" /><svg width=\"25.974%\" x=\"25.974%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"25%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.5%\" y1=\"20px\" y2=\"48px\" /><svg width=\"40%\" x=\"25%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">little</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"45%\" y1=\"20px\" y2=\"48px\" /><svg width=\"35%\" x=\"65%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">mouse</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.5%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"38.961%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.49351%\" x=\"51.9481%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">who</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">WP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.1948%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.49351%\" x=\"58.4416%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">was</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.6883%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.09091%\" x=\"64.9351%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">after</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.4805%\" y1=\"20px\" y2=\"48px\" /><svg width=\"25.974%\" x=\"74.026%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"25%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.5%\" y1=\"20px\" y2=\"48px\" /><svg width=\"35%\" x=\"25%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">fresh</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"42.5%\" y1=\"20px\" y2=\"48px\" /><svg width=\"40%\" x=\"60%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">cheese</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"80%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"87.013%\" y1=\"20px\" y2=\"48px\" /></svg>"
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Textblob**"
      ],
      "metadata": {
        "id": "4NC7JyJ4yx5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "E2auiJeDyk9N"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"John used to be very happy if he works on some AI related projects.\""
      ],
      "metadata": {
        "id": "acAsxzMp0MSk"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(TextBlob(sent).words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBmQOJ6l0U15",
        "outputId": "d03975fc-67f9-4883-f98d-c0fbf58d1fb1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['John', 'used', 'to', 'be', 'very', 'happy', 'if', 'he', 'works', 'on', 'some', 'AI', 'related', 'projects']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TextBlob(sent).tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwjJSMQ00Yzb",
        "outputId": "900aa6de-c0c4-45ec-8dac-5f696ba56ec4"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('John', 'NNP'), ('used', 'VBD'), ('to', 'TO'), ('be', 'VB'), ('very', 'RB'), ('happy', 'JJ'), ('if', 'IN'), ('he', 'PRP'), ('works', 'VBZ'), ('on', 'IN'), ('some', 'DT'), ('AI', 'NNP'), ('related', 'JJ'), ('projects', 'NNS')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TextBlob(sent).sentiment.polarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cHRMYPy0eXQ",
        "outputId": "71066ffa-8c76-4bb5-b56d-cf570be005ae"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"John is sad and upset today\"\n",
        "print(TextBlob(sent).sentiment.polarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM6BA7Pp0jsE",
        "outputId": "133fc1a9-6024-4d0c-a02f-edfe0ae0c984"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"John is travelling today\"\n",
        "print(TextBlob(sent).sentiment.polarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsrv7EuU0qvW",
        "outputId": "b0e04ff9-5426-4de7-a7ea-3c75890c7687"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hugging Face Token**"
      ],
      "metadata": {
        "id": "BH3JyWH0_c64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "#userdata.get('hf_token')"
      ],
      "metadata": {
        "id": "BWL8FQds0uwa"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Using huggingface_hub"
      ],
      "metadata": {
        "id": "ZYd_H8f2_lWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceApi"
      ],
      "metadata": {
        "id": "YDmYDqtl_iLa"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN = userdata.get('hf_token')\n",
        "MODEL = 'openai/gpt-oss-20b'\n",
        "\n",
        "inference = InferenceApi(repo_id = MODEL,token = HF_TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUQe4eB4_sw6",
        "outputId": "243e9837-9f20-4472-df52-c758a7c9e3d8"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Call\n",
        "output = inference(inputs=\"What do you know about Chat GPT?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "SLbtHd54AHBx",
        "outputId": "6e5be760-35fe-474b-9be1-e9806bae8749"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "text/plain; charset=utf-8 output type is not implemented yet. You can pass `raw_response=True` to get the raw `Response` object and parse the output by yourself.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2610299403.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"What do you know about Chat GPT?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/inference_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, params, data, raw_response)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             raise NotImplementedError(\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;34mf\"{content_type} output type is not implemented yet. You can pass\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;34m\" `raw_response=True` to get the raw `Response` object and parse the\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: text/plain; charset=utf-8 output type is not implemented yet. You can pass `raw_response=True` to get the raw `Response` object and parse the output by yourself."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfXLSFX7DLSO",
        "outputId": "f219e1c2-fc34-4487-e2eb-98f6bf363dd2"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.32.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-0.32.0-py3-none-any.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key='')\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"openai/gpt-oss-20b\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What do you know about Chat GPT?\"\n",
        "      }\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_completion_tokens=8192,\n",
        "    top_p=1,\n",
        "    reasoning_effort=\"medium\",\n",
        "    stream=True,\n",
        "    stop=None\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqPT-Wx8AVgc",
        "outputId": "3809b751-6f80-4010-8889-c2bda3dcc0e3"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**ChatGPT in a nutshell**\n",
            "\n",
            "| Topic | Key points |\n",
            "|-------|------------|\n",
            "| **What it is** | ChatGPT is a conversational AI built on OpenAI’s *Generative Pre‑trained Transformer* (GPT) family. It can understand and generate natural‑language text that feels like a human‑to‑human chat. |\n",
            "| **Model base** | • GPT‑4 (the current “ChatGPT‑4” model) – a decoder‑only transformer with a very large number of parameters (hundreds of billions, exact count undisclosed).<br>• Earlier versions: GPT‑3.5, GPT‑3 (175 B params). |\n",
            "| **Training pipeline** | 1. **Pre‑training** on a massive, diverse text corpus (web pages, books, code, etc.) to learn statistical patterns of language.<br>2. **Supervised fine‑tuning** where human reviewers rank model responses to a set of prompts.<br>3. **Reinforcement Learning from Human Feedback (RLHF)** that optimizes the model to produce answers that align with human preferences. |\n",
            "| **How it works** | • Tokenizes input text (≈ 4‑5 kB per token) and predicts the next token in a sequence. <br>• Uses self‑attention to weigh all tokens in the context window (8 k tokens for GPT‑3.5, 32 k for GPT‑4). <br>• Generates text one token at a time until a stop condition is met. |\n",
            "| **Interaction style** | ChatGPT follows a *prompt‑response* pattern. The API (or web UI) uses a **message‑role** format: <br>• **system** – sets overall behavior (“You are a helpful assistant.”)<br>• **user** – the user’s input<br>• **assistant** – the model’s reply. |\n",
            "| **Common uses** | • Writing & editing (emails, reports, creative stories)<br>• Code generation & debugging (Python, JavaScript, SQL, etc.)<br>• Summaries, translations, and paraphrasing<br>• Educational tutoring, language learning, interview prep<br>• Brainstorming, idea generation, business planning<br>• Customer support chatbots, virtual assistants<br>• Content moderation, data labeling, and quick research |\n",
            "| **Strengths** | • Handles a wide range of topics with decent depth.<br>• Adapts quickly to new prompts (few‑shot/zero‑shot learning).<br>• Can maintain context over several turns (within the token window).<br>• Easily integrated via the OpenAI API (ChatCompletion endpoint). |\n",
            "| **Limitations** | • **Hallucinations**: can produce plausible‑sounding but factually incorrect or fabricated information.<br>• **Biases**: reflects biases present in training data; may produce biased or offensive content if not filtered.<br>• **Static knowledge**: no real‑time internet access; knowledge cutoff (≈ 2023 for GPT‑4).<br>• **Token limit**: long documents exceed the context window, causing truncation.<br>• **No deep reasoning**: can struggle with complex multi‑step logic or highly domain‑specific problems. |\n",
            "| **Safety & Ethics** | • OpenAI implements content filters to block disallowed content (violence, hate, sexual content, etc.).<br>• The model is designed to refuse or safe‑halt when faced with requests for disallowed content.<br>• Developers must add their own guardrails (rate limiting, user‑identity checks, content moderation) when deploying in production. |\n",
            "| **API usage** | • `ChatCompletion` endpoint: send a list of messages (role + content).<br>• Adjustable parameters: `temperature` (creativity), `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`.<br>• Rate limits and pricing vary by model (e.g., GPT‑4 is more expensive). |\n",
            "| **Future directions** | • Larger context windows (e.g., 128 k tokens in some research prototypes).<br>• Fine‑tuning for specific industries (legal, medical, finance).<br>• Multimodal capabilities (text + image/voice).<br>• Improved alignment and factuality via better RLHF signals and retrieval‑augmented generation. |\n",
            "\n",
            "---\n",
            "\n",
            "### Quick FAQ\n",
            "\n",
            "| Question | Answer |\n",
            "|----------|--------|\n",
            "| **Can ChatGPT browse the web?** | No. It can only use the knowledge it learned during training. |\n",
            "| **Is it 100 % accurate?** | No. It can hallucinate or misinterpret. Verify critical facts. |\n",
            "| **Can I ask it for medical advice?** | It can provide general information, but it is not a substitute for a licensed professional. |\n",
            "| **How do I keep it safe?** | Combine OpenAI’s content filter with your own moderation, monitor outputs, and restrict sensitive use cases. |\n",
            "| **Can it code?** | Yes, it can generate code snippets and help debug, but always review the output for correctness and security. |\n",
            "| **What’s the difference between GPT‑3.5 and GPT‑4?** | GPT‑4 has more parameters, a larger context window, better reasoning, and improved alignment, but it is also more expensive to use. |\n",
            "\n",
            "---\n",
            "\n",
            "**Bottom line:** ChatGPT is a powerful, general‑purpose language model that can simulate conversation, write text, generate code, and more. It excels at rapid, flexible responses but must be used with an awareness of its knowledge limits, potential for hallucinations, and ethical considerations. If you’re planning to integrate it into a product or service, start with a small pilot, monitor outputs closely, and layer your own safety and compliance controls."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J6ZrN8gWDJcV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}